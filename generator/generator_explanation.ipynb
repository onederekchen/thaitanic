{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation on generator design choices. \n",
    "\n",
    "**Don't look if you don't want spoilers!**\n",
    "\n",
    "This notebook covers the design choices of the data generator (and changes for the regenerator). If you're looking for an exploratory analysis of the data, look [HERE] If you're looking for the experimental plan and analysis, look [HERE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generator philsophy\n",
    "\n",
    "We don't have ThaiTanic's actual data, but we can use some market sizing tricks to get a decent estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular times (by hour)\n",
    "\n",
    "Used Google popular times to estimate orders per hour. Assigned weights and assumed 0 value gives 50%.\n",
    "\n",
    "Huge variance - busiest day is almost 3x as busy as least busy day.\n",
    "\n",
    "---\n",
    "\n",
    "I noticed Google has \"popular_times\" values for the restaurant. There isn't really a scale, but I can use these to approximate restaurant occupancy to the hour instead of to the day.\n",
    "\n",
    "I'm not sure how specific these are to 2020 - they seem a little low to me, but I figured it's fine because I'm just estimating and I'll throw in variance anyway.\n",
    "\n",
    "##### (!) should I add in variance in the years? and the months?! how did i miss that?\n",
    "\n",
    "##### (!) add in a visualization that shows the min/max values vs. the average weighted values we have? that would be a cool graph! (would belong in this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market sizing\n",
    "\n",
    "Seating count, dining time, delivery/takeout\n",
    "\n",
    "The idea was to size the total amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (!) need to validate the total number of orders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual/seasonal multipliers\n",
    "\n",
    "Year multiplier, summer/winter month multiplier. Mostly negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance for additional item in order\n",
    "\n",
    "If ordering starter or dessert, there's a chance for an additional item. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chance for increased order quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating by hour\n",
    "\n",
    "Tried by month (because csvs are by month), but \"accuracy\" to the hour made more sense. Added variance with normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights for menu (by category, by item)\n",
    "\n",
    "Categories have weights, and then within the category the items have weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data REgenerator\n",
    "\n",
    "We regenerate fresh data to simulate collection of user data. \n",
    "\n",
    "Current plan is slight random variance in weights, and printing out the weight used to a .txt file which I won't look at until after the analysis. The goal is to evaluate whether or not the value went up or down, and whether it's statistically significant or just noise (e.g. the change we made actually had some impact). \n",
    "\n",
    "I'll look at the randomly printed value afterwards to compare. Might make a note: based on the test results, I would say this is statistically significant and would recommend this change going forward. Bonus: since it's a simulation, I'll try to guess the weight (not really sure if this is worth anything since there's so many random variation all over the place, but it's just for fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity ordered is big at 1, then 2, then follows a normal distribution after that. It sticks out a bit that as many people ordered 9 quantity of an item as 3 quantity. Maybe a geometric distribution would be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
