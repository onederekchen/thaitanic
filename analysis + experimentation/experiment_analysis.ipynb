{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial commit\n",
    "\n",
    "**Whether or not I sharpen my sales analysis, I can start on this**\n",
    "\n",
    "We design the experiments based on the recommendations from the data analysis. And then when the data from the implementation comes back, we interpret it and give an insight.\n",
    "\n",
    "So input is testing recommendations, and output is insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on A/B testing\n",
    "\n",
    "A/B testing is a specific type of user testing that involves one population two versions of something at the same time. This is different than traditional user testing where a restaurant might make a change for a month and see if the results are better or worse than expected. \n",
    "\n",
    "Because of this, A/B testing is usually used on software products, or in cases where there are large populations AND you can easily show two versions of a product. The closest you can probably get in a restaurant is giving half of a restaurant one menu and another half a different menu (you would be worried about logistics and having a large enough sample size or enough past data), or having two identical restaurants in areas with populations with comparable tastes (e.g. a McDonalds in two parts of the same city - you would still want enough historical data to be able to tell the two apart though). \n",
    "\n",
    "We're generating data, so it's possible for us to simulate situations that are otherwise impossible, like the same restaurant changing hours but only for 50% of the population. I'll use this to A/B test different menus (which would be possible but logistically challenging). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B test suggestions\n",
    "\n",
    "We got some suggestions from the data_analysis notebook. We'll take a closer look at how to actually test it here, and evaluate the results.\n",
    "\n",
    "\n",
    "1. Change weekdays?\n",
    "2. Change items offered (combos?)\n",
    "3. Change menu?\n",
    "\n",
    "Menu change is a free a/b test - usually you'd want to split the test with the same population but that's logistically a lot to ask for a real-time business like a restaurant. But we do have a lot of past data, so we just try the new menu for a month and see if it performs outside of a confidence interval.\n",
    "\n",
    "In the next notebook, we'll do analysis and assume we have no knowledge of this generator. We will approach it like a real, independent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hours change\n",
    "\n",
    "We'll start with traditional user-testing that's realistic for a restaurant. We have a lot of past data, and based on our analysis, we think having our closed day on monday instead of \n",
    "\n",
    "### Downsides to this\n",
    "\n",
    "Obviously, the data is generated, so even though we can simulate the data and measure the difference, it's not as messy as real user data. Also, the weights are mostly picked on my own biases.\n",
    "\n",
    "Also, you can't really test hours changing on a restaurant. The closest you can probably get is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menu change\n",
    "\n",
    "##### MY AI: ADD MENU, REVALUE GENERATOR!\n",
    "\n",
    "We'll test an actual change the real restaurant made: a menu update. \n",
    "\n",
    "**Here's** the old menu, **here's** the new menu.\n",
    "\n",
    "\n",
    "\n",
    "A thought on implementation: we're not actually implementing this, but if we were, we would have to carefully think this through. How will we confirm who has what menu? At first, it seems like we could just divide the restaurant in half, it's a smaller space so that might not work well. Instead, we could have a mark on the menu they used to order, and enter that as a comment when entering their order. An A or B would be fine, or you could put a sticker on the menu. As long as it works to differentiate, and you can consistently do it. \n",
    "\n",
    "I would expect our dataframe for the month to be the same, except there's one additional column with an A or B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other things to test\n",
    "\n",
    "We could test pretty much anything else we want to - the thing to be careful with is that testing is expensive (lots of time and resources, and people who can do end-to-end testing are usually pricey to hire), and could go wrong (which is the point of A/B testing - you get a 1:1 control so it's kind of like diversifying).\n",
    "\n",
    "These tests have essentially been toy models, but if this data was real and we wanted to dig deeper, we could test this things too:\n",
    "- \n",
    "\n",
    "Don't forget that the point of testing is to validate a belief. If you notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rosemary suggests grouping by mean to test the weekdays. --> some stats refreshing would be a good idea to do a good job on this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
