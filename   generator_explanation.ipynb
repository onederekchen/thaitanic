{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generator explanation**\n",
    "\n",
    "<!-- **Why I wanted to do this project**\n",
    "\n",
    "Before I learned to program / decided I wanted to learn to do data science, I ran user-testing programs for hardware products at a tech company. There are a lot of people getting into data science, and while I still feel like a beginner at programming, I'm pretty confident in my business background. So I wanted a project to show that. When I first started, this project had almost nothing to do with business, but it just kind of bled through - the connections were already there.\n",
    "\n",
    "- so maybe it's better to just say that? think about the message and try to get it clear.\n",
    "- I also like this stuff anyway - ask me about the case study I wrote for a business fraternity in 2018. (I picked this restaurant because I thought the name was funny - I was going to use another restaurant I also wrote a case about called the Himalayan Chimney, but they changed their website to just an ordering screen because of covid, which wasn't as fun).\n",
    "\n",
    "**Showcasing A/B testing is hard**\n",
    "\n",
    "Anyway, it's hard to showcase A/B testing because you need a product and users. And every company seems to want A/B testing experience. So instead of giving up, I found a sneaky way around it. When a company does A/B testing, they just look at the data to see how users interact with a change. So instead of actually implementing a change and looking at the data, we can just regenerate data for a month and pretend that's the sales data from the users. It's just order data, so it's not as good as real-time user data (like click-through-rates or stuff like that), but it's not likely most restaurants will have that kind of data either - it's a nice, simple example.\n",
    "\n",
    "- also gives us a chance to talk about the difference between a/b testing and other types of user testing\n",
    "- don't forget about the pitfalls of A/B testing! How does that apply to this case?\n",
    "\n",
    "**Notebooks are independent** (!) will probably move to readme\n",
    "\n",
    "In each workbook, we assume we have no knowledge of other notebooks.\n",
    "\n",
    "A truer chronological workflow might look like this:\n",
    "\n",
    "1. Get data\n",
    "    1. Write generator, generate data [data_generator.py]\n",
    "    2. Document generator design [generator_explanation.ipynb]\n",
    "    \n",
    "    \n",
    "2. Explore data\n",
    "    1. Explore, validate data (suggest business recs / potential tests) [data_analysis.ipynb]\n",
    "    \n",
    "    \n",
    "3. Design test\n",
    "    1. Design experiment for accepted tests [experiment_analysis.ipynb]\n",
    "    \n",
    "    \n",
    "4. Implement test\n",
    "    1. Regenerate data for test [data_generator.py]\n",
    "    2. Document re-generator design [generator_explanation.ipynb]\n",
    "    \n",
    "    \n",
    "5. Evaluate findings\n",
    "    1. Analyze experiment, explain findings [experiment_analysis.ipynb] -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the design choices for the data generator. **Don't look if you don't want spoilers on the dataset!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents: \n",
    "- Data generator overview\n",
    "- Two key questions (market sizing, order sizing)\n",
    "- Improvements & other notes\n",
    "<!-- - Evaluate data -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator creates order data for a real Thai restaurant by estimating the number of customers and what they are likely to order. Its expected output is a monthly .csv file per specified month/year.\n",
    "\n",
    "The number of customers is based on the restaurant's maximum possible output multiplied by Google's popular times occupancy hourly estimation. What the customers order is based on weights I assigned to the menu categories and items (I picked based on what I thought customers in the area might really order, and checked with some friends so hopefully it's not too biased). These factors both have separate random multipliers and fixed monthly and yearly weights.\n",
    "\n",
    "I'll quickly overview the columns and their distributions and then talk more about how I made my assumptions.\n",
    "\n",
    "<!-- having core assumptions here might be a better format - check how research papers are outlined... -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fields\n",
    "- **Order ID**: Unique order ID (orders with more than one item are a second line with the same ID).\n",
    "        Number of orders per hour is based on estimated occupancy from popular times. There's some randomness too. And some annual/seasonal values. We'll explore this one further below.\n",
    "    \n",
    "    \n",
    "- **Item**: Menu item ordered. See menu for possible values.\n",
    "        I assigned weights to each menu category and item. The generator randomly selects a category, then an item from that category. \n",
    "\n",
    "\n",
    "- **Quantity Ordered**: Amount of the menu item ordered.\n",
    "    Follows exponential distribution. There's a chance to order an additional item.\n",
    "\n",
    "- **Price Each**: Price per item ordered, same as listed on menu.\n",
    "\n",
    "\n",
    "- **Order Date**: Order date and time in YYYY-MM-DD hh:mm:ss format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main factors that affect how much revenue the restaurant generates:\n",
    "1. How many orders the restaurant gets per month (external)\n",
    "2. How much people spend per order (internal)\n",
    "\n",
    "<!-- Each of these factors  -->\n",
    "\n",
    "Here's a revenue model to help visualize the process. The two main things that affect sales are the number of sales the restaurant gets, and how much each sale is worth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue model: two key questions\n",
    "\n",
    "![](..\\thaitanic/revenue_model.jpg)\n",
    "\n",
    "Pictured is a revenue model to help us understand the key drivers of sales. The two key factors are how many customers the restaurant gets, and what they order. Focusing on the factors that affect those drivers helps us create more realistic data.\n",
    "\n",
    "<!-- link to [slides](https://docs.google.com/presentation/d/1PKQtxfG-HTdD3Nb0Tvh_jYqEWOlPUWJRwaHT3MVXpoM/edit?usp=sharing)  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How many orders does the restaurant get per month?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating market size\n",
    "\n",
    "\n",
    "We want to find out the maximum amount of orders the restaurant might get per month. We can get this by multiplying the restaurant's max capacity by the number of orders the resturant can handle, which is the average meal length. \n",
    "\n",
    "##### Restaurant capacity\n",
    "\n",
    "Based on photos from \n",
    "[Yelp](https://www.yelp.com/biz_photos/thaitanic-streetfood-sausalito-2)\n",
    "and \n",
    "[Google](https://www.google.com/maps/uv?pb=!1s0x80858451b4f18a91:0xa561eb4585721e9d!3m1!7e115!4s)\n",
    "(can't rehost images due to copyright), it looks like there are **30 seats total** (20 indoor, 10 outdoor).\n",
    "\n",
    "##### # of servable meals + takeout\n",
    "\n",
    "Google indicates the average time spent per meal is 15 minutes to an hour. One hour seems high for an average, and 30 minutes seems a bit low, but since they do takeout, I'm okay with using 30 minutes. If we wanted to estimate for takeout more accurately, we might use kitchen output instead of physical capacity but that seems much more complicated for a small improvement that would be tough to measure too.\n",
    "\n",
    "The restaurant is open for 8 hours a day, so we're saying they can serve at max 16 meals per seat per day. At 30 seats, we estimate that they can serve (30 * 16 =) **480 meals per day**. This sounds high, but it's really the amount of meals the restaurant would be able to fulfill if they had lines out the door from the minute they open to the minute they close. \n",
    "\n",
    "In the actual data, we probably wouldn't want to see any numbers above 400 except for maybe the busiest hours of the busiest days of the busiest months.\n",
    "\n",
    "<!-- For reference...? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating actual demand\n",
    "\n",
    "Google also provides \"Popular Times\" estimates. Here are the Wednesday (least busy day) and Saturday (most busy day).\n",
    "\n",
    "**Wednesday popular times**\n",
    "\n",
    "![](..\\thaitanic/data/popular_times/wednesday.PNG) \n",
    "\n",
    "**Saturday Popular times**\n",
    "\n",
    "![](..\\thaitanic/data/popular_times/saturday.PNG)\n",
    "\n",
    "The difference between days in this data is HUGE - the busiest day is almost three times as busy as the least busy day. It's hard to make concrete assumptions because Google doesn't provide a scale for the data - based on this, you would assume the restaurant is empty for most hours of most weekdays. I don't think that's totally true, so I assumed they were relative values. \n",
    "\n",
    "I interpreted the bottom line to be 50% occupancy, and each additional line to be 25% occupancy. This means an hour with over two bars of demand is over 100% occupancy, which would just be represented as a wait time. I then divided this value by 100 to turn it into a multiplier, and assigned one of these multipliers to every hour of every weekday. My method can be represented by this formula:\n",
    "\n",
    "$f(x) = \\frac{25x + 50}{100}$\n",
    "\n",
    "The values I pulled are specific to 2020 so there's a chance they're uncharacteristically low, but I checked against restaurants in areas not heavily affected by covid and they seemed similar enough to just keep.\n",
    "\n",
    "Note that if we didn't have Google's data, we could just estimate by the hour, or generate data on a per-day basis (which I'm glad we didn't do because that would be much too uniform). We might also be able to increase accuracy by evaluating the local population, but at that point I would rather sit outside with a clipboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Annual, seasonal weights\n",
    "\n",
    "I also added weights to decrease the number of orders. Annually, I just wanted the restaurant to be trending upwards. I checked some google market research for this.\n",
    "\n",
    "I wanted the holiday months to be really high, and the summer months to be slightly higher. The rest ofthe months could be whatever, I put them at 80 (so at 50% occupancy all day - zero bars - we're now looking at about 190 orders. It works out pretty well to start from a high amount and use decreasing multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps us size the total market. The idea is that we can estimate the total realistic output from the restaurant, and then apply modifiers to decrease from there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compensating for quantity ordered distribution\n",
    "\n",
    "Using an exponential distribution in quantity ordered increases our total quantity ordered by about 66%, so we need a negative modifier to compensate for that. I feel comfortable that our number of orders accurately represents the number of orders per seat.\n",
    "\n",
    "I used 0.7 as a modifer insted of 0.6 (1/1.66) because there still are some guests who order more than one dish per seat. Seems reasonable since no guests who order less than one dish per seat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What do people spend on orders?\n",
    "\n",
    "I peeked at yelp too for input and considered scraping them for ratings, but their robot.txt disallows it.\n",
    "\n",
    "This part was really easy... I just added in the weights from the menu. \n",
    "\n",
    "### Menu weights\n",
    "\n",
    "I copied the menu and added weights per category and then per item. The category weights were basd on whether or not I thought someone would want an item from there if they actually ordered. It also had to do with how good the items were. \n",
    "\n",
    "Then for the items in the category, there are relative weights that determine which item should be preferred once the category is selected.\n",
    "\n",
    "I peeked at the local population and went with my gut on what I thought would actually be ordered (it hurt me to rank Pad Thai above Pad See Ew). I also asked some friends for input on this. I initially considered asking a bunch of people on the internet to tell me what they would actually order, but I figured it was overkill (might be fun for another project though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order quantity \n",
    "\n",
    "I kind of just added this in at the end, but it felt like the values were really low so I threw in a chance to order more of an item.\n",
    "\n",
    "And also a chance to order a second item. Both of these increase total quantity ordered and therefore sales, but I think it's fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a second item to an order\n",
    "\n",
    "There's a small chance to order a second item. It's really high if it's a dessert, and it's kind of high if there's an appetizer. I actually forgot about the appetizer part, then rediscovered it in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Order IDs don't match Order Date. They're all within the hour, but they're random. It doesn't really make sense that the first order would be 10 minutes from closing, while the next order after that is halfway through the shift. The solution is probably to generate from a minute basis, but it seems like a small enough detail to skip for now. **I think this is the only real flaw in the data** - the rest are just minor inaccuracies.\n",
    "- Code is a bit slow. There are some list comprehensions in the loop that aren't very elegant because I was accessing multi-element lists in a dictionary. It felt like too much to explicitly get lists of the weight element from the dictionary, so I put it in the loop. I'm sure there's also a cleaner way I could've added options for additional orders, but will revisit when I have a deeper understanding of programming.\n",
    "- I think my usage of nested loops is appropriate here, but wow it's ugly to see that many nested loops. I'm sure I'll realize a better way to have built that in the future.\n",
    "- This applies to all of the notebooks in this project, but I think they get messy when there's too much content, and I'm a bit verbose. I'll work on it.\n",
    "- I used an exponential distribution on quantity ordered which isn't wrong, but it feels too uniformly exponential. I would imagine most orders to be one, then two through four, then some ives and sixes, then almost nothing, then a bunch of orders from corporate catering around 10. Instead, it follows a smooth exponential curve which is a bit too pretty.\n",
    "- I calculated the orders based on a single person, and changed the quantity ordered to an exponential distribution without checking how that affects the total quantity ordered. The data is a bit conservative, but the orders and therefore sales are bit higher than I intended. But it's a family style place so it's not too bad. \n",
    "\n",
    "If you're reading this and have advice for any of the above (or any feedback on the project at all, really!) please let me know. Pull requests or emails work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other notes\n",
    "\n",
    "I did 2017 - 2019 data because I didn't want to touch covid in this dataset. The effects are complicated enough that mocking data doesn't seem to be the best fit (if you really wanted to, you could use machine learning to emulate datasets instead).\n",
    "\n",
    "You might be able to make covid data by setting the weight to a random (low) value that can sometimes be zero. But it feels out of the scope of this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random state\n",
    "\n",
    "I didn't use a random state because random.choices SPECIFICALLY does not work with np.random.RandomState(). random.choices worked fine. It looks like it was added to the random library but isn't supported by numpy yet. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
